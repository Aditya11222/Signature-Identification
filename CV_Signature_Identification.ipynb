{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5-fSaTHAiqc",
        "outputId": "b62fe331-ebb2-492f-b74b-4fca7598bf46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnEB_l_UA50R"
      },
      "source": [
        "##Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lH_aUpRKA2oW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.cm as cm\n",
        "from scipy import ndimage\n",
        "from skimage.measure import regionprops\n",
        "from skimage import io\n",
        "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import keras\n",
        "from scipy import ndimage\n",
        "from skimage.filters import threshold_otsu\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQGoaQwvBEdd"
      },
      "source": [
        "##Import Datasets for real and forged images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zBZjcJW8BBru"
      },
      "outputs": [],
      "source": [
        "genuine_image_paths = \"/content/drive/MyDrive/signature_identification/real\"\n",
        "forged_image_paths =  \"/content/drive/MyDrive/signature_identification/forged\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyg3gvTYBoyb"
      },
      "source": [
        "## Preprocessing the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B8iUsDj_CH-A"
      },
      "outputs": [],
      "source": [
        "def rgb_to_grey(img):\n",
        "    # Convert RGB image to grayscale\n",
        "    grey_img = np.mean(img, axis=2)\n",
        "    return grey_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1ImUAy-tCoLU"
      },
      "outputs": [],
      "source": [
        "# The function grey_to_binary takes a grayscale image (img) as input.\n",
        "# It applies a Gaussian blur to the image using ndimage.gaussian_filter to remove small components or noise.\n",
        "# It calculates the threshold value using threshold_otsu.\n",
        "# The grayscale image is then binarized using this threshold value, and the binary image is returned.\n",
        "\n",
        "def grey_to_binary(img):\n",
        "    # Convert grayscale image to binary\n",
        "    blur_radius = 0.8\n",
        "    blurred_img = ndimage.gaussian_filter(img, blur_radius)  # Remove small components or noise\n",
        "    threshold_value = threshold_otsu(blurred_img)\n",
        "    binary_img = blurred_img > threshold_value\n",
        "    binary_img = np.logical_not(binary_img)\n",
        "    return binary_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vVy2YLRTDB6g"
      },
      "outputs": [],
      "source": [
        "# Combined the RGB to grayscale conversion and display into one step using rgb2gray from skimage.color.\n",
        "# Calculated the threshold value using threshold_otsu from skimage.filters.\n",
        "# Simplified the display of images using matplotlib.pyplot.imshow and matplotlib.pyplot.show.\n",
        "# Used more descriptive variable names like grey_img, binary_img, and sign_img for better readability.\n",
        "\n",
        "\n",
        "def preprocess_image(path, img=None, display=True):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "\n",
        "    if display:\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "\n",
        "    grey_img = rgb2gray(img)  # Convert RGB to grayscale\n",
        "    if display:\n",
        "        plt.imshow(grey_img, cmap=cm.Greys_r)\n",
        "        plt.show()\n",
        "\n",
        "    threshold_value = threshold_otsu(grey_img)  # Calculate threshold value\n",
        "    binary_img = grey_img > threshold_value  # Convert grayscale to binary\n",
        "    if display:\n",
        "        plt.imshow(binary_img, cmap=cm.Greys_r)\n",
        "        plt.show()\n",
        "\n",
        "    r, c = np.where(binary_img == 1)  # Find rows and columns with white pixels (value 1)\n",
        "    # Create a bounding box around the signature\n",
        "    sign_img = binary_img[r.min():r.max(), c.min():c.max()]\n",
        "    if display:\n",
        "        plt.imshow(sign_img, cmap=cm.Greys_r)\n",
        "        plt.show()\n",
        "\n",
        "    return sign_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-KhxEMzEW8v"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "37ZXdMpiETQZ"
      },
      "outputs": [],
      "source": [
        "# We use np.count_nonzero(img) to count the number of True pixels (white) in the binary image, which is more efficient than looping through each pixel.\n",
        "# The total number of pixels in the image is calculated using img.shape[0] * img.shape[1].\n",
        "# The ratio of white pixels to total pixels (ratio) is then calculated and returned.\n",
        "\n",
        "def calculate_ratio(img):\n",
        "    # Count the number of True pixels (white) in the binary image\n",
        "    num_white_pixels = np.count_nonzero(img)\n",
        "\n",
        "    # Calculate the total number of pixels in the image\n",
        "    total_pixels = img.shape[0] * img.shape[1]\n",
        "\n",
        "    # Calculate and return the ratio of white pixels to total pixels\n",
        "    ratio = num_white_pixels / total_pixels\n",
        "    return ratio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "secHPf9CE4Xx"
      },
      "outputs": [],
      "source": [
        "# We use np.argwhere(img == 1) to find the coordinates of white pixels more efficiently.\n",
        "# The number of white pixels is determined by the length of the white_pixels array.\n",
        "# The centroid is calculated using np.mean(white_pixels, axis=0) / img.shape to get the centroid coordinates normalized by the image dimensions.\n",
        "# The function returns the x and y coordinates of the centroid.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_centroid(img):\n",
        "    # Count the number of white pixels and calculate the centroid\n",
        "    white_pixels = np.argwhere(img == 1)\n",
        "    num_white_pixels = len(white_pixels)\n",
        "    centroid = np.mean(white_pixels, axis=0) / img.shape\n",
        "\n",
        "    return centroid[0], centroid[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RwdmMnMQFTtq"
      },
      "outputs": [],
      "source": [
        "# We import regionprops from skimage.measure to calculate region properties of the binary image.\n",
        "# The function calculate_eccentricity_solidity takes a binary image (img) as input.\n",
        "# It calculates the region properties using regionprops, assuming there is only one region in the image (regions[0]).\n",
        "# The function then returns the eccentricity and solidity of the region.\n",
        "\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "def calculate_eccentricity_solidity(img):\n",
        "    # Calculate region properties for the binary image\n",
        "    regions = regionprops(img.astype(\"int8\"))\n",
        "\n",
        "    # Return the eccentricity and solidity of the first region (assuming only one region in the image)\n",
        "    return regions[0].eccentricity, regions[0].solidity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uAxJFVCaFc24"
      },
      "outputs": [],
      "source": [
        "# Calculated the centroid, standard deviation, skewness, and kurtosis using NumPy operations directly on arrays, improving efficiency and readability.\n",
        "\n",
        "def calculate_skewness_kurtosis(img):\n",
        "    h, w = img.shape\n",
        "    x = np.arange(w)  # cols value\n",
        "    y = np.arange(h)  # rows value\n",
        "\n",
        "    # Calculate projections along the x and y axes\n",
        "    xp = np.sum(img, axis=0)\n",
        "    yp = np.sum(img, axis=1)\n",
        "\n",
        "    # Calculate centroid\n",
        "    cx = np.sum(x * xp) / np.sum(xp)\n",
        "    cy = np.sum(y * yp) / np.sum(yp)\n",
        "\n",
        "    # Calculate standard deviation\n",
        "    x2 = (x - cx) ** 2\n",
        "    y2 = (y - cy) ** 2\n",
        "    sx = np.sqrt(np.sum(x2 * xp) / np.sum(img))\n",
        "    sy = np.sqrt(np.sum(y2 * yp) / np.sum(img))\n",
        "\n",
        "    # Calculate skewness\n",
        "    x3 = (x - cx) ** 3\n",
        "    y3 = (y - cy) ** 3\n",
        "    skewx = np.sum(xp * x3) / (np.sum(img) * sx ** 3)\n",
        "    skewy = np.sum(yp * y3) / (np.sum(img) * sy ** 3)\n",
        "\n",
        "    # Calculate Kurtosis\n",
        "    x4 = (x - cx) ** 4\n",
        "    y4 = (y - cy) ** 4\n",
        "    kurtx = np.sum(xp * x4) / (np.sum(img) * sx ** 4) - 3\n",
        "    kurty = np.sum(yp * y4) / (np.sum(img) * sy ** 4) - 3\n",
        "\n",
        "    return (skewx, skewy), (kurtx, kurty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5MbF45EEGijB"
      },
      "outputs": [],
      "source": [
        "def getFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = preprocess_image(path, display=display)\n",
        "    ratio = calculate_ratio(img)\n",
        "    centroid = calculate_centroid(img)\n",
        "    eccentricity, solidity = calculate_eccentricity_solidity(img)\n",
        "    skewness, kurtosis = calculate_skewness_kurtosis(img)\n",
        "    return ratio, centroid, eccentricity, solidity, skewness, kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w5vcnxSFG1P_"
      },
      "outputs": [],
      "source": [
        "def getCSVFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = preprocess_image(path, display=display)\n",
        "    temp = getFeatures(path, display=display)\n",
        "    features = (\n",
        "        temp[0],\n",
        "        temp[1][0],\n",
        "        temp[1][1],\n",
        "        temp[2],\n",
        "        temp[3],\n",
        "        temp[4][0],\n",
        "        temp[4][1],\n",
        "        temp[5][0],\n",
        "        temp[5][1]\n",
        "    )\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeOHzWeOG-WM"
      },
      "source": [
        "## Saving the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413aHUJML9yS",
        "outputId": "e5884873-ff4e-4022-910e-9ac40c31ab31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving features for person id- 001\n",
            "Saving features for person id- 002\n",
            "Saving features for person id- 003\n",
            "Saving features for person id- 004\n",
            "Saving features for person id- 005\n",
            "Saving features for person id- 006\n",
            "Saving features for person id- 007\n",
            "Saving features for person id- 008\n",
            "Saving features for person id- 009\n",
            "Saving features for person id- 010\n",
            "Saving features for person id- 011\n",
            "Saving features for person id- 012\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def makeCSV(genuine_image_paths, forged_image_paths):\n",
        "    features_folder = '/content/drive/MyDrive/signature_identification/Features'\n",
        "    training_folder = os.path.join(features_folder, 'Training')\n",
        "    testing_folder = os.path.join(features_folder, 'Testing')\n",
        "\n",
        "    folders_to_create = [features_folder, training_folder, testing_folder]\n",
        "    for folder in folders_to_create:\n",
        "        if not os.path.exists(folder):\n",
        "            os.mkdir(folder)\n",
        "            print(f'New folder \"{folder}\" created')\n",
        "\n",
        "    for person in range(1, 13):\n",
        "        per = ('00' + str(person))[-3:]\n",
        "        print('Saving features for person id-', per)\n",
        "\n",
        "        training_file_path = os.path.join(training_folder, f'training_{per}.csv')\n",
        "        testing_file_path = os.path.join(testing_folder, f'testing_{per}.csv')\n",
        "\n",
        "        with open(training_file_path, 'w') as training_handle, \\\n",
        "             open(testing_file_path, 'w') as testing_handle:\n",
        "            training_handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "            testing_handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "\n",
        "            # Genuine signatures\n",
        "            for i in range(3):\n",
        "                source = os.path.join(genuine_image_paths, f'{per}{per}_00{i}.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                training_handle.write(','.join(map(str, features)) + ',1\\n')\n",
        "\n",
        "            for i in range(3, 5):\n",
        "                source = os.path.join(genuine_image_paths, f'{per}{per}_00{i}.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                testing_handle.write(','.join(map(str, features)) + ',1\\n')\n",
        "\n",
        "            # Forged signatures\n",
        "            for i in range(3):\n",
        "                source = os.path.join(forged_image_paths, f'021{per}_00{i}.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                training_handle.write(','.join(map(str, features)) + ',0\\n')\n",
        "\n",
        "            for i in range(3, 5):\n",
        "                source = os.path.join(forged_image_paths, f'021{per}_00{i}.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                testing_handle.write(','.join(map(str, features)) + ',0\\n')\n",
        "\n",
        "genuine_image_paths = '/content/drive/MyDrive/signature_identification/real'\n",
        "forged_image_paths = '/content/drive/MyDrive/signature_identification/forged'\n",
        "makeCSV(genuine_image_paths, forged_image_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66yYUetFp3a3",
        "outputId": "45482863-2eed-425b-fabb-c37908704ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving features for person id- 001\n",
            "Saving features for person id- 002\n",
            "Saving features for person id- 003\n",
            "Saving features for person id- 004\n",
            "Saving features for person id- 005\n",
            "Saving features for person id- 006\n",
            "Saving features for person id- 007\n",
            "Saving features for person id- 008\n",
            "Saving features for person id- 009\n",
            "Saving features for person id- 010\n",
            "Saving features for person id- 011\n",
            "Saving features for person id- 012\n"
          ]
        }
      ],
      "source": [
        "makeCSV(genuine_image_paths,forged_image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkJSqUm1Y3Yi"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ns9ucJfcOCDk"
      },
      "outputs": [],
      "source": [
        "def testing(path):\n",
        "    feature = getCSVFeatures(path)\n",
        "    if not(os.path.exists('/content/drive/MyDrive/signature_identification/Features/Testing')):\n",
        "        os.mkdir('/content/drive/MyDrive/signature_identification/Features/Testing')\n",
        "    with open('/content/drive/MyDrive/signature_identification/Features/Testing/testcsv.csv', 'w') as handle:\n",
        "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
        "        handle.write(','.join(map(str, feature))+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BoXKNM36uIcu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ops = tf.compat.v1\n",
        "ops.reset_default_graph()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7rIDhMm-wqG",
        "outputId": "3a21b1f8-68e1-4a4f-8de6-6ad92db88e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter person's id : 006\n",
            "Enter path of signature image : /content/drive/MyDrive/signature_identification/real/006006_002.png\n",
            "Result: Genuine Image\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import time\n",
        "\n",
        "# Define ops for TensorFlow 1.x compatibility\n",
        "ops = tf.compat.v1\n",
        "ops.reset_default_graph()\n",
        "\n",
        "n_input = 9\n",
        "train_person_id = input(\"Enter person's id : \")\n",
        "test_image_path = input(\"Enter path of signature image : \")\n",
        "train_path = '/content/drive/MyDrive/signature_identification/Features/Training/training_' + train_person_id + '.csv'\n",
        "\n",
        "def readCSV(train_path):\n",
        "    df = pd.read_csv(train_path)\n",
        "    train_input = np.array(df.values[:, :n_input])\n",
        "    train_input = train_input.astype(np.float32, copy=False)\n",
        "    correct = np.array(df.values[:, n_input:])\n",
        "    corr_train = keras.utils.to_categorical(correct, 2)\n",
        "    return train_input, corr_train\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 1000\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 7\n",
        "n_hidden_2 = 10\n",
        "n_hidden_3 = 30\n",
        "n_classes = 2\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1], seed=1)),\n",
        "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.random.normal([n_hidden_2, n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_hidden_1, n_classes], seed=2))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random.normal([n_hidden_1], seed=3)),\n",
        "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.random.normal([n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_classes], seed=4))\n",
        "}\n",
        "\n",
        "# Create model\n",
        "def multilayer_perceptron(x):\n",
        "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
        "    return out_layer\n",
        "\n",
        "# Construct model\n",
        "logits = multilayer_perceptron(X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.math.squared_difference(logits, Y))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# For accuracies\n",
        "pred = tf.nn.softmax(logits)\n",
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "def extract_features(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (3, 3))  # Resize to match the input size of the model\n",
        "    image_flat = image.flatten()\n",
        "    return image_flat\n",
        "\n",
        "def determine_signature(train_path, test_image_path):\n",
        "    train_input, corr_train = readCSV(train_path)\n",
        "    test_image_features = extract_features(test_image_path)\n",
        "\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for epoch in range(training_epochs):\n",
        "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
        "            if cost < 0.0001:\n",
        "                break\n",
        "        prediction = pred.eval({X: test_image_features.reshape((1, n_input))})\n",
        "        if prediction[0][1] > prediction[0][0]:\n",
        "            return \"Genuine Image\"\n",
        "        else:\n",
        "            return \"Forged Image\"\n",
        "\n",
        "result = determine_signature(train_path, test_image_path)\n",
        "print(\"Result:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPxsr1rBpqty",
        "outputId": "d472cd2c-9d64-468a-efa9-7e163f4deac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter person's id : 006\n",
            "Enter path of signature image : /content/drive/MyDrive/signature_identification/real/006006_002.png\n",
            "Result: Genuine Image\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import time\n",
        "\n",
        "# Disable eager execution\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Define ops for TensorFlow 1.x compatibility\n",
        "ops = tf.compat.v1\n",
        "ops.reset_default_graph()\n",
        "\n",
        "n_input = 9\n",
        "train_person_id = input(\"Enter person's id : \")\n",
        "test_image_path = input(\"Enter path of signature image : \")\n",
        "train_path = '/content/drive/MyDrive/signature_identification/Features/Training/training_' + train_person_id + '.csv'\n",
        "\n",
        "def readCSV(train_path):\n",
        "    df = pd.read_csv(train_path)\n",
        "    train_input = np.array(df.values[:, :n_input])\n",
        "    train_input = train_input.astype(np.float32, copy=False)\n",
        "    correct = np.array(df.values[:, n_input:])\n",
        "    corr_train = keras.utils.to_categorical(correct, 2)\n",
        "    return train_input, corr_train\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 1000\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 7\n",
        "n_hidden_2 = 10\n",
        "n_hidden_3 = 30\n",
        "n_classes = 2\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1], seed=1)),\n",
        "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.random.normal([n_hidden_2, n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_hidden_1, n_classes], seed=2))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random.normal([n_hidden_1], seed=3)),\n",
        "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.random.normal([n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_classes], seed=4))\n",
        "}\n",
        "\n",
        "# Create model\n",
        "def multilayer_perceptron(x):\n",
        "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
        "    return out_layer\n",
        "\n",
        "# Construct model\n",
        "logits = multilayer_perceptron(X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.math.squared_difference(logits, Y))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# For accuracies\n",
        "pred = tf.nn.softmax(logits)\n",
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "def extract_features(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (3, 3))  # Resize to match the input size of the model\n",
        "    image_flat = image.flatten()\n",
        "    return image_flat\n",
        "\n",
        "def determine_signature(train_path, test_image_path):\n",
        "    train_input, corr_train = readCSV(train_path)\n",
        "    test_image_features = extract_features(test_image_path)\n",
        "\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for epoch in range(training_epochs):\n",
        "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
        "            if cost < 0.0001:\n",
        "                break\n",
        "        prediction = pred.eval({X: test_image_features.reshape((1, n_input))})\n",
        "        if prediction[0][1] > prediction[0][0]:\n",
        "            return \"Genuine Image\"\n",
        "        else:\n",
        "            return \"Forged Image\"\n",
        "\n",
        "result = determine_signature(train_path, test_image_path)\n",
        "print(\"Result:\", result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
